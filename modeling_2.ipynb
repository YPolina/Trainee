{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from validation_step import *\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from xgboost import XGBRegressor\n",
    "from sklearn.metrics import root_mean_squared_error"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Loading of datasets\n",
    "data = pd.read_csv('data.csv')\n",
    "categories = pd.read_csv('item_categories.csv')\n",
    "items = pd.read_csv('items.csv')\n",
    "shops = pd.read_csv('shops.csv')\n",
    "test = pd.read_csv('./competitive-data-science-predict-future-sales/test.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Transformation of test set\\n\",\n",
    "merge_params = [[items, 'item_id'], [categories, 'item_category_id'], [shops, 'shop_id']]\n",
    "\n",
    "for df_merge, column in merge_params:\n",
    "    test = test.merge(df_merge, on = f'{column}', how = 'left')\n",
    "\n",
    "test['date_block_num'] = 34\n",
    "test['year'] = 2015\n",
    "test['month'] = 11\n",
    "    \n",
    "columns = ['item_category_id', 'main_category_id', 'minor_category_id',\n",
    "    'date_block_num', 'item_id', 'month', \n",
    "    'year', 'shop_id', 'city_id']\n",
    "test = test.loc[:, columns]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "#According to the task conditions, True target values are clipped in the range [0,20]\n",
    "data.item_cnt_month = data.item_cnt_month.clip(0,20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\User\\AppData\\Local\\Temp\\ipykernel_92908\\3268138665.py:2: FutureWarning: The behavior of pd.concat with len(keys) != len(objs) is deprecated. In a future version this will raise instead of truncating to the smaller of the two sequences\n",
      "  data = pd.concat([data, test], ignore_index=True, sort=False, keys=columns)\n"
     ]
    }
   ],
   "source": [
    "#Merge Train and Test sets\n",
    "data = pd.concat([data, test], ignore_index=True, sort=False, keys=columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_shop_ids = test['shop_id'].unique()\n",
    "test_item_ids = test['item_id'].unique()\n",
    "# Only shops that exist in test\n",
    "data = data[data['shop_id'].isin(test_shop_ids)]\n",
    "# Only items that exist in test\n",
    "data = data[data['item_id'].isin(test_item_ids)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Pipeline with feature enfineering, column trasformation, obtaining a complete data set, validation,\n",
    "categorical_features = ['item_category_id', 'main_category_id', 'minor_category_id', 'shop_id']\n",
    "target_log_transformation = ['item_cnt_month']\n",
    "\n",
    "col_lags_dict = {'date_item_avg_item_cnt': [1,2,3,6,12], 'date_shop_avg_item_cnt': [1,2,3,6,12], 'date_shop_cat_avg_item_cnt': [1], 'date_cat_avg_item_cnt': [1],\n",
    "    'date_minor_cat_avg_item_cnt': [1], 'date_main_cat_avg_item_cnt': [1], 'date_city_avg_item_cnt': [1], 'date_item_avg_item_price': [1,2,3,6], 'delta_revenue': [1]}\n",
    "\n",
    "#Pipeline for feature engineering(revenue, shop_history, minor_catregory_history, lags)\n",
    "pipeline_1 = pipeline_1(col_lags_dict)\n",
    "pipeline_1.fit(data)\n",
    "data = pipeline_1.transform(data)\n",
    "\n",
    "#Pipeline for log transformation and encoding of categorical features\n",
    "pipeline_2 = pipeline_2(target_log_transformation, categorical_features)\n",
    "pipeline_2.fit(data)\n",
    "transformed_data = pipeline_2.transform(data)\n",
    "\n",
    "#Adding results from 2nd pipeline\\n\",\n",
    "transformed_columns = ['item_cnt_month_log', 'item_category_id', 'main_category_id', 'minor_category_id', 'shop_id']\n",
    "data[transformed_columns] = transformed_data\n",
    "\n",
    "#Save in dataframe needed columns and removing features that can cause data/target leakage\n",
    "columns = ['date_block_num', 'shop_id', 'item_id', 'item_category_id',\n",
    "       'main_category_id', 'minor_category_id', 'month', 'year', 'city_id', 'shop_history',\n",
    "           'minor_category_history', 'date_item_avg_item_cnt_lag_1',\n",
    "           'date_item_avg_item_cnt_lag_2', 'date_item_avg_item_cnt_lag_3',\n",
    "           'date_item_avg_item_cnt_lag_6', 'date_item_avg_item_cnt_lag_12',\n",
    "           'date_shop_avg_item_cnt_lag_1', 'date_shop_avg_item_cnt_lag_2',\n",
    "           'date_shop_avg_item_cnt_lag_3', 'date_shop_avg_item_cnt_lag_6',\n",
    "           'date_shop_avg_item_cnt_lag_12', 'date_shop_cat_avg_item_cnt_lag_1',\n",
    "           'date_cat_avg_item_cnt_lag_1', 'date_minor_cat_avg_item_cnt_lag_1',\n",
    "           'date_main_cat_avg_item_cnt_lag_1', 'date_city_avg_item_cnt_lag_1',\n",
    "           'date_item_avg_item_price_lag_1', 'date_item_avg_item_price_lag_2',\n",
    "           'date_item_avg_item_price_lag_3', 'date_item_avg_item_price_lag_6',\n",
    "           'delta_revenue_lag_1', 'item_cnt_month_log']\n",
    "data = data.loc[:, columns].fillna(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation successful, data is valid.\n"
     ]
    }
   ],
   "source": [
    "#Data Validation\n",
    "non_negative_columns = ['date_block_num', 'shop_id', 'item_id', 'item_category_id',\n",
    "       'main_category_id', 'minor_category_id', 'month', 'year', 'city_id', 'shop_history',\n",
    "           'minor_category_history', 'date_item_avg_item_cnt_lag_1',\n",
    "           'date_item_avg_item_cnt_lag_2', 'date_item_avg_item_cnt_lag_3',\n",
    "           'date_item_avg_item_cnt_lag_6', 'date_item_avg_item_cnt_lag_12',\n",
    "           'date_shop_avg_item_cnt_lag_1', 'date_shop_avg_item_cnt_lag_2',\n",
    "           'date_shop_avg_item_cnt_lag_3', 'date_shop_avg_item_cnt_lag_6',\n",
    "           'date_shop_avg_item_cnt_lag_12', 'date_shop_cat_avg_item_cnt_lag_1',\n",
    "           'date_cat_avg_item_cnt_lag_1', 'date_minor_cat_avg_item_cnt_lag_1',\n",
    "           'date_main_cat_avg_item_cnt_lag_1', 'date_city_avg_item_cnt_lag_1',\n",
    "           'date_item_avg_item_price_lag_1', 'date_item_avg_item_price_lag_2',\n",
    "           'date_item_avg_item_price_lag_3', 'date_item_avg_item_price_lag_6',\n",
    "           'item_cnt_month_log']\n",
    "\n",
    "validation = Validator(non_negative_columns = non_negative_columns)\n",
    "\n",
    "try:\n",
    "    validated_data = validation.fit_transform(data)\n",
    "    print(\"Validation successful, data is valid.\")\n",
    "except ValueError as e:\n",
    "    print(f\"Validation error: {e}\")\n",
    "except TypeError as e:\n",
    "    print(f\"Type error: {e}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "validated_data.to_csv('full_data.csv', index = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "k = 3 \n",
    "kf = KFold(n_splits=k, shuffle=True, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Train/test split\n",
    "\n",
    "X_test = data[data.date_block_num == 34].drop('item_cnt_month_log', axis = 1)\n",
    "\n",
    "X = data[data.date_block_num != 34].drop('item_cnt_month_log', axis = 1)\n",
    "y = data[data.date_block_num != 34]['item_cnt_month_log']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<strong>Linear Regression</strong>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Linear Regression\n",
      "RMSE for split 1: 0.413\n",
      "RMSE for split 2: 0.413\n",
      "RMSE for split 3: 0.416\n",
      "Mean RMSE for all splits: 0.414\n"
     ]
    }
   ],
   "source": [
    "n = 0\n",
    "rmse = []\n",
    "numerical_features = ['date_item_avg_item_cnt_lag_1', 'date_item_avg_item_cnt_lag_2',\n",
    "       'date_item_avg_item_cnt_lag_3', 'date_item_avg_item_cnt_lag_6',\n",
    "       'date_item_avg_item_cnt_lag_12', 'date_shop_avg_item_cnt_lag_1',\n",
    "       'date_shop_avg_item_cnt_lag_2', 'date_shop_avg_item_cnt_lag_3',\n",
    "       'date_shop_avg_item_cnt_lag_6', 'date_shop_avg_item_cnt_lag_12',\n",
    "       'date_shop_cat_avg_item_cnt_lag_1', 'date_cat_avg_item_cnt_lag_1',\n",
    "       'date_minor_cat_avg_item_cnt_lag_1', 'date_main_cat_avg_item_cnt_lag_1',\n",
    "       'date_city_avg_item_cnt_lag_1', 'date_item_avg_item_price_lag_1',\n",
    "       'date_item_avg_item_price_lag_2', 'date_item_avg_item_price_lag_3',\n",
    "       'date_item_avg_item_price_lag_6', 'delta_revenue_lag_1']\n",
    "categorical_features = ['date_block_num', 'shop_id', 'item_id', 'item_category_id',\n",
    "       'main_category_id', 'minor_category_id', 'month', 'year', 'city_id',\n",
    "       'shop_history', 'minor_category_history']\n",
    "\n",
    "preprocessor = ColumnTransformer(\n",
    "    transformers=[\n",
    "        ('num', StandardScaler(), numerical_features),\n",
    "        ('cat', 'passthrough', categorical_features)\n",
    "    ])\n",
    "\n",
    "pipeline = Pipeline(steps=[\n",
    "    ('preprocessor', preprocessor),\n",
    "    ('regressor', LinearRegression())\n",
    "])\n",
    "\n",
    "\n",
    "print('Linear Regression')\n",
    "\n",
    "for train_idxs, val_idxs in kf.split(X):\n",
    "\n",
    "    X_train, X_val = X.iloc[train_idxs], X.iloc[val_idxs]\n",
    "    y_train, y_val = y.iloc[train_idxs], y.iloc[val_idxs]\n",
    "    \n",
    "    pipeline.fit(X_train, y_train)\n",
    "    y_pred = pipeline.predict(X_val)\n",
    "    rmse.append(root_mean_squared_error(y_pred, y_val))\n",
    "    print(f'RMSE for split {n+1}: {rmse[n]:.3f}')\n",
    "    n += 1\n",
    "print(f'Mean RMSE for all splits: {np.mean(rmse):.3f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "pipeline.fit(X, y)\n",
    "y_pred_linregr = np.round(np.expm1(pipeline.predict(X_test)),2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "submission = pd.DataFrame({'ID': np.arange(len(y_pred_linregr)), 'item_cnt_month': y_pred_linregr})\n",
    "submission.to_csv('submission.csv', index = False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "_**Submission result for Linear Regression: 1.54639**_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<strong>RandomForestRegressor</strong>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RandomForestRegressor\n",
      "RMSE for split 1: 0.341\n",
      "RMSE for split 2: 0.340\n",
      "RMSE for split 3: 0.340\n",
      "Mean RMSE for all splits: 0.340\n"
     ]
    }
   ],
   "source": [
    "n = 0\n",
    "rmse = []\n",
    "model = RandomForestRegressor()\n",
    "\n",
    "print('RandomForestRegressor')\n",
    "\n",
    "for train_idxs, val_idxs in kf.split(X):\n",
    "\n",
    "    X_train, X_val = X.iloc[train_idxs], X.iloc[val_idxs]\n",
    "    y_train, y_val = y.iloc[train_idxs], y.iloc[val_idxs]\n",
    "    \n",
    "    model.fit(X_train, y_train)\n",
    "    y_pred = model.predict(X_val)\n",
    "    rmse.append(root_mean_squared_error(y_pred, y_val))\n",
    "    print(f'RMSE for split {n+1}: {rmse[n]:.3f}')\n",
    "    n += 1\n",
    "print(f'Mean RMSE for all splits: {np.mean(rmse):.3f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.fit(X, y)\n",
    "y_pred_rfregr = np.round(np.expm1(model.predict(X_test)),2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "submission['item_cnt_month'] = y_pred_rfregr\n",
    "submission.to_csv('submission.csv', index = False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "_**Submission result for RFRegression: 1.75864**_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<strong>XGBRegressor</strong>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "XGBRegressor\n",
      "RMSE for split 1: 0.356\n",
      "RMSE for split 2: 0.356\n",
      "RMSE for split 3: 0.356\n",
      "Mean RMSE for all splits: 0.356\n"
     ]
    }
   ],
   "source": [
    "n = 0\n",
    "rmse = []\n",
    "model = XGBRegressor()\n",
    "\n",
    "print('XGBRegressor')\n",
    "\n",
    "for train_idxs, val_idxs in kf.split(X):\n",
    "\n",
    "    X_train, X_val = X.iloc[train_idxs], X.iloc[val_idxs]\n",
    "    y_train, y_val = y.iloc[train_idxs], y.iloc[val_idxs]\n",
    "    \n",
    "    model.fit(X_train, y_train)\n",
    "    y_pred = model.predict(X_val)\n",
    "    rmse.append(root_mean_squared_error(y_pred, y_val))\n",
    "    print(f'RMSE for split {n+1}: {rmse[n]:.3f}')\n",
    "    n += 1\n",
    "print(f'Mean RMSE for all splits: {np.mean(rmse):.3f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.fit(X, y)\n",
    "y_pred_xgbregressor = np.round(np.expm1(model.predict(X_test)),2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "submission['item_cnt_month'] = y_pred_xgbregressor\n",
    "submission.to_csv('submission.csv', index = False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "_**Submission result for XGBRegression: 1.55268**_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "XGBRegressor\n",
      "RMSE for split 1: 0.336\n",
      "RMSE for split 2: 0.334\n",
      "RMSE for split 3: 0.338\n",
      "Mean RMSE for all splits: 0.336\n"
     ]
    }
   ],
   "source": [
    "n = 0\n",
    "rmse = []\n",
    "\n",
    "model = XGBRegressor(n_estimators=500,\n",
    "                    eta = 0.1,\n",
    "                    max_depth = 8,\n",
    "                    reg_lambda = 2)\n",
    "\n",
    "print('XGBRegressor')\n",
    "\n",
    "for train_idxs, val_idxs in kf.split(X):\n",
    "\n",
    "    X_train, X_val = X.iloc[train_idxs], X.iloc[val_idxs]\n",
    "    y_train, y_val = y.iloc[train_idxs], y.iloc[val_idxs]\n",
    "    \n",
    "    model.fit(X_train, y_train)\n",
    "    y_pred = model.predict(X_val)\n",
    "    rmse.append(root_mean_squared_error(y_pred, y_val))\n",
    "    print(f'RMSE for split {n+1}: {rmse[n]:.3f}')\n",
    "    n += 1\n",
    "print(f'Mean RMSE for all splits: {np.mean(rmse):.3f}')\n",
    "\n",
    "y_pred_xgbregressor = np.expm1(model.predict(X_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "submission['item_cnt_month'] = np.round(y_pred_xgbregressor,2)\n",
    "submission.to_csv('submission.csv', index = False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "_**Submission result for XGBRegression after some hyperpar.added: 1.57257**_"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
