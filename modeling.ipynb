{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 340,
   "metadata": {},
   "outputs": [],
   "source": [
    "import baseline\n",
    "import importlib\n",
    "importlib.reload(baseline)\n",
    "from baseline import *\n",
    "import numpy as np \n",
    "import pandas as pd\n",
    "from sklearn.preprocessing import LabelEncoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mem. usage decreased to 14.47 Mb (80.0% reduction)\n",
      "Mem. usage decreased to  1.43 Mb (70.8% reduction)\n",
      "Mem. usage decreased to  0.00 Mb (40.7% reduction)\n",
      "Mem. usage decreased to  0.27 Mb (59.4% reduction)\n",
      "Mem. usage decreased to  0.00 Mb (42.4% reduction)\n"
     ]
    }
   ],
   "source": [
    "#Data loading and reduce memory usage by changing dtypes\n",
    "train = reduce_mem_usage(pd.read_csv('train.csv'))\n",
    "test = reduce_mem_usage(pd.read_csv('test.csv'))\n",
    "shops = reduce_mem_usage(pd.read_csv('shops.csv'))\n",
    "items = reduce_mem_usage(pd.read_csv('items.csv'))\n",
    "categories = reduce_mem_usage(pd.read_csv('item_categories.csv'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Data is valid'"
      ]
     },
     "execution_count": 125,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Check if our train data is valid\n",
    "column_types = {'date_block_num': 'int8', 'shop_id': 'int8', 'item_id': 'int16', 'item_price': 'float16', 'item_cnt_day': 'float16'}\n",
    "values_ranges = {'date_block_num': (0, 33), 'shop_id': (0, 59), 'item_id': (0, 22169), 'item_price': (0.07, 42980.0), 'item_cnt_day': (0, 669)}\n",
    "Validator(column_types = column_types, value_ranges = values_ranges, check_missing = True, check_duplicates=True).fit_transform(train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Target - item_cnt_month\n",
    "target_group = (train.groupby(['date_block_num', 'shop_id', 'item_id'])['item_cnt_day']\n",
    "                .sum().rename('item_cnt_month').reset_index())\n",
    "#From EDA step we do not see linear dependency between item_cnt_month and item_price.\n",
    "#Feature 'revenue' will give us more imformation about target\n",
    "train['revenue'] = train['item_price'] * train['item_cnt_day']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "According to EDA: we do have a lot of data without full range during analysing period\n",
    "and also our test set contains shop_id&item_id pairs that are nor presented in train set at all\n",
    "'''\n",
    "columns = ['date_block_num', 'shop_id', 'item_id']\n",
    "full_data = full_data_creation(df = train, agg_group = columns, periods = train.date_block_num.nunique())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Merge between full data and train set\n",
    "full_data = full_data.merge(target_group, on = columns, how = 'left')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\User\\AppData\\Local\\Temp\\ipykernel_78472\\370786687.py:4: FutureWarning: The behavior of pd.concat with len(keys) != len(objs) is deprecated. In a future version this will raise instead of truncating to the smaller of the two sequences\n",
      "  full_data = pd.concat([full_data, test], keys = columns, ignore_index=True, sort = False)\n"
     ]
    }
   ],
   "source": [
    "#test set concatenation with full_data\n",
    "test['date_block_num'] = 34\n",
    "del test['ID']\n",
    "full_data = pd.concat([full_data, test], keys = columns, ignore_index=True, sort = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "We need:\n",
    "1. fill all missing values as item&shop pairs + test set have been added\n",
    "2. clip our target variable - original condition\n",
    "'''\n",
    "full_data = full_data.fillna(0)\n",
    "full_data['item_cnt_month'] = full_data['item_cnt_month'].clip(0,20).astype(np.float16)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Merge with other datasets\n",
    "full_data = full_data.merge(shops, on = 'shop_id', how = 'left')\n",
    "full_data = full_data.merge(items, on = 'item_id', how = 'left')\n",
    "full_data = full_data.merge(categories, on = 'item_category_id', how = 'left')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Columns we are planning to work\n",
    "Work_columns = ['date_block_num', 'shop_id', 'item_cnt_month', 'item_id', 'city_id', 'item_category_id', 'main_category_id','minor_category_id']\n",
    "full_data = full_data.loc[:, Work_columns]\n",
    "\n",
    "#As we make transformations during DQL with shop_id, we will encode it with LabelEncoding\n",
    "full_data['shop_id'] = LabelEncoder().fit_transform(full_data['shop_id'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Feature exctraction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "metadata": {},
   "outputs": [],
   "source": [
    "#From EDA we see a lot of missings in different features during the date period\n",
    "#We will create feature_history with number of months (for example for shop) that feature exists\n",
    "full_data = history_features(df = full_data, agg = 'shop_id', new_feature = 'shop_history')\n",
    "full_data = history_features(df = full_data, agg = 'item_id', new_feature = 'item_history')\n",
    "full_data = history_features(df = full_data, agg = 'minor_category_id', new_feature = 'minor_category_history')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Features from aggregations\n",
    "agg_list = [\n",
    "    (['date_block_num', 'item_category_id'], 'avg_item_cnt_per_cat', {'item_cnt_month': 'mean'}),\n",
    "    (['date_block_num', 'city_id'], 'avg_item_cnt_per_city', {'item_cnt_month': 'mean'}),\n",
    "    (['date_block_num', 'shop_id'], 'avg_item_cnt_per_shop', {'item_cnt_month': 'mean'}),\n",
    "    (['date_block_num', 'item_category_id', 'shop_id'], 'avg_item_cnt_per_cat_per_shop', {'item_cnt_month': 'mean'}),\n",
    "    (['date_block_num', 'item_id'], 'avg_item_cnt_per_item', {'item_cnt_month': 'mean'}),\n",
    "    (['date_block_num', 'item_category_id', 'shop_id'], 'med_item_cnt_per_cat_per_shop', {'item_cnt_month': 'median'}),\n",
    "    (['date_block_num', 'main_category_id'], 'avg_item_cnt_per_main_cat', {'item_cnt_month': 'mean'}),\n",
    "    (['date_block_num', 'minor_category_id'], 'avg_item_cnt_per_minor_cat', {'item_cnt_month': 'mean'}),\n",
    "    (['date_block_num', 'shop_id', 'item_id'], 'avg_item_cnt_per_date_block', {'item_cnt_month': 'mean'}),\n",
    "    (['item_id'], 'first_sales_date_block', {'item_cnt_month': 'min'})\n",
    "]\n",
    "\n",
    "\n",
    "for agg, new_col, aggregation in agg_list:\n",
    "    full_data = feat_from_agg(full_data, agg, new_col, aggregation)\n",
    "    \n",
    "\n",
    "\n",
    "full_data['first_sales_date_block'] = full_data['first_sales_date_block'].fillna(34)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Lags of aggregational features\n",
    "#All aggregations will be delted to avoid data leakage\n",
    "lag_dict = {'avg_item_cnt_per_cat': [1], 'avg_item_cnt_per_shop': [1], 'avg_item_cnt_per_item': [1],\n",
    "            'avg_item_cnt_per_city': [1], 'avg_item_cnt_per_cat_per_shop': [1], \n",
    "            'med_item_cnt_per_cat_per_shop': [1], 'avg_item_cnt_per_main_cat': [1],\n",
    "            'avg_item_cnt_per_minor_cat': [1], 'avg_item_cnt_per_date_block': [1,2,3],\n",
    "            'item_cnt_month': [1]}\n",
    "\n",
    "\n",
    "for feature, lags in lag_dict.items():\n",
    "    full_data = lag_features(df = full_data, shift_col = feature, lags = lags)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Features with last sales\n",
    "full_data = last_sales(df = full_data, new_feature = 'item_shop_last_sale', item_shop = True)\n",
    "full_data = last_sales(df = full_data, new_feature = 'item_last_sale', item_shop = False)\n",
    "\n",
    "#On basis of items last sales - first sales\n",
    "full_data['item_shop_first_sale'] = full_data['date_block_num'] - full_data.groupby(['item_id','shop_id'])['date_block_num'].transform('min')\n",
    "full_data['item_first_sale'] = full_data['date_block_num'] - full_data.groupby('item_id')['date_block_num'].transform('min')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Revenue&Item Price Features and their lags\n",
    "train = train.merge(items.loc[:, ['item_id', 'item_category_id']], on = 'item_id', how = 'left')\n",
    "train = train.merge(shops.loc[:, ['shop_id', 'city_id']], on = 'shop_id', how = 'left')\n",
    "\n",
    "agg_list = [\n",
    "    (['date_block_num', 'item_category_id', 'shop_id'], 'sales_per_category_per_shop', {'revenue': 'sum'}),\n",
    "    (['date_block_num', 'shop_id'], 'sales_per_shop', {'revenue': 'sum'}),\n",
    "    (['date_block_num', 'item_id'], 'sales_per_item', {'revenue': 'sum'}),\n",
    "    (['item_id'], 'avg_item_price', {'item_price': 'mean'}),\n",
    "    (['date_block_num','item_id'], 'avg_item_price_month', {'item_price': 'mean'})\n",
    "]\n",
    "\n",
    "\n",
    "for agg, new_col, aggregation in agg_list:\n",
    "    train = feat_from_agg(train, agg, new_col, aggregation)\n",
    "\n",
    "lag_dict = {'sales_per_category_per_shop': [1], 'sales_per_shop': [1],\n",
    "            'sales_per_item': [1], 'avg_item_price': [1], \n",
    "            'avg_item_price_month': [1]}\n",
    "\n",
    "for feature, lags in lag_dict.items():\n",
    "    train = lag_features(df = train, shift_col = feature, lags = lags)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Merging results\n",
    "del train['item_price']\n",
    "del train['revenue']\n",
    "del train['item_category_id']\n",
    "del train['city_id']\n",
    "del train['item_cnt_day']\n",
    "full_data = full_data.merge(train, on = ['date_block_num', 'shop_id', 'item_id'], how = 'left')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "metadata": {},
   "outputs": [],
   "source": [
    "full_data = full_data.replace([np.inf, -np.inf], np.nan).fillna(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 338,
   "metadata": {},
   "outputs": [],
   "source": [
    "full_data.to_csv('full_data.csv', index = False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Train/Test split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Validation\n",
    "tss = TimeSeriesSplit(n_splits=3)\n",
    "\n",
    "X_test = full_data[full_data.date_block_num == 34].drop('item_cnt_month', axis = 1)\n",
    "\n",
    "X = full_data[full_data.date_block_num != 34].drop('item_cnt_month', axis = 1)\n",
    "y = full_data[full_data.date_block_num != 34]['item_cnt_month']\n",
    "tss = TimeSeriesSplit(n_splits=3)\n",
    "\n",
    "for train_idxs, val_idxs in tss.split(X):\n",
    "\n",
    "    X_train, X_val = X.iloc[train_idxs], X.iloc[val_idxs]\n",
    "    y_train, y_val = y.iloc[train_idxs], y.iloc[val_idxs]\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Training\n",
    "X_train = full_data[~full_data.date_block_num.isin([33,34])]\n",
    "y_train = X_train['item_cnt_month']\n",
    "del X_train['item_cnt_month']\n",
    "\n",
    "X_val = full_data[full_data['date_block_num']==33]\n",
    "y_val = X_val['item_cnt_month']\n",
    "del X_val['item_cnt_month']\n",
    "\n",
    "X_test = full_data[full_data['date_block_num']==34].drop(columns='item_cnt_month')\n",
    "X_test = X_test.reset_index()\n",
    "del X_test['index']"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
