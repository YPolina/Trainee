{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import validation_step\n",
    "import importlib\n",
    "importlib.reload(validation_step)\n",
    "from validation_step import *\n",
    "from etl_eda import *\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.model_selection import TimeSeriesSplit\n",
    "from sklearn.dummy import DummyRegressor\n",
    "from sklearn.metrics import root_mean_squared_error"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Loading of datasets\n",
    "data = load('data.csv')\n",
    "categories = load('item_categories.csv')\n",
    "items = load('items.csv')\n",
    "shops = load('shops.csv')\n",
    "test = load('./competitive-data-science-predict-future-sales/test.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Transformation of test set\n",
    "merge_params = [[items, 'item_id'], [categories, 'item_category_id'], [shops, 'shop_id']]\n",
    "\n",
    "for df_merge, column in merge_params:\n",
    "        test = test.merge(df_merge, on = f'{column}', how = 'left')\n",
    "\n",
    "test['date_block_num'] = 34\n",
    "test['year'] = 2015\n",
    "test['month'] = 11\n",
    "\n",
    "columns = ['item_category_id', 'main_category_id', 'minor_category_id',\n",
    "       'date_block_num', 'item_id', 'month',\n",
    "       'year', 'shop_id', 'city_id']\n",
    "test = test.loc[:, columns]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\User\\AppData\\Local\\Temp\\ipykernel_104244\\3268138665.py:2: FutureWarning: The behavior of pd.concat with len(keys) != len(objs) is deprecated. In a future version this will raise instead of truncating to the smaller of the two sequences\n",
      "  data = pd.concat([data, test], ignore_index=True, sort=False, keys=columns)\n"
     ]
    }
   ],
   "source": [
    "#Merge Train and Test sets\n",
    "data = pd.concat([data, test], ignore_index=True, sort=False, keys=columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "item_id_list  = list(test.item_id)\n",
    "shop_id_list = list(test.shop_id)\n",
    "data = data[(data.item_id.isin(item_id_list)) & (data.shop_id.isin(shop_id_list))]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Pipeline with feature enfineering, column trasformation, obtaining a complete data set, validation\n",
    "categorical_features = ['item_category_id', 'main_category_id', 'minor_category_id', 'shop_id']\n",
    "target_log_transformation = ['item_cnt_month']\n",
    "\n",
    "col_lags_dict = {'date_item_avg_item_cnt': [1,2,3,6,12], 'date_shop_avg_item_cnt': [1,2,3,6,12], 'date_shop_cat_avg_item_cnt': [1], 'date_cat_avg_item_cnt': [1], \n",
    "'date_minor_cat_avg_item_cnt': [1], 'date_main_cat_avg_item_cnt': [1], 'date_city_avg_item_cnt': [1], 'date_item_avg_item_price': [1,2,3,6], 'delta_revenue': [1]}\n",
    "\n",
    "date_block_num = 34\n",
    "\n",
    "#Pipeline for feature engineering(revenue, shop_history, minor_catregory_history, lags) and obtaining complete data on all item&shop pairs\n",
    "pipeline_1 = pipeline_1(date_block_num, col_lags_dict)\n",
    "pipeline_1.fit(data)\n",
    "data = pipeline_1.transform(data)\n",
    "\n",
    "#Pipeline for log transformation and encoding of categorical features\n",
    "pipeline_2 = pipeline_2(target_log_transformation, categorical_features)\n",
    "pipeline_2.fit(data)\n",
    "transformed_data = pipeline_2.transform(data)\n",
    "\n",
    "#Merging results of 2 pipelines\n",
    "transformed_columns = ['item_cnt_month_log', 'item_category_id', 'main_category_id', 'minor_category_id', 'shop_id']\n",
    "data[transformed_columns] = transformed_data\n",
    "\n",
    "#Save in dataframe needed columns and removing features that can cause data/target leakage\n",
    "columns = ['date_block_num', 'shop_id', 'item_id', 'item_category_id',\n",
    "       'main_category_id', 'minor_category_id', 'month', 'year', 'city_id', 'shop_history',\n",
    "       'minor_category_history', 'date_item_avg_item_cnt_lag_1',\n",
    "       'date_item_avg_item_cnt_lag_2', 'date_item_avg_item_cnt_lag_3',\n",
    "       'date_item_avg_item_cnt_lag_6', 'date_item_avg_item_cnt_lag_12',\n",
    "       'date_shop_avg_item_cnt_lag_1', 'date_shop_avg_item_cnt_lag_2',\n",
    "       'date_shop_avg_item_cnt_lag_3', 'date_shop_avg_item_cnt_lag_6',\n",
    "       'date_shop_avg_item_cnt_lag_12', 'date_shop_cat_avg_item_cnt_lag_1',\n",
    "       'date_cat_avg_item_cnt_lag_1', 'date_minor_cat_avg_item_cnt_lag_1',\n",
    "       'date_main_cat_avg_item_cnt_lag_1', 'date_city_avg_item_cnt_lag_1',\n",
    "       'date_item_avg_item_price_lag_1', 'date_item_avg_item_price_lag_2',\n",
    "       'date_item_avg_item_price_lag_3', 'date_item_avg_item_price_lag_6',\n",
    "       'delta_revenue_lag_1', 'item_cnt_month_log']\n",
    "data = data.loc[:, columns]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = data.fillna(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation successful, data is valid.\n"
     ]
    }
   ],
   "source": [
    "#Data Validation\n",
    "non_negative_columns = ['date_block_num', 'shop_id', 'item_id', 'item_category_id',\n",
    "       'main_category_id', 'minor_category_id', 'month', 'year', 'city_id',\n",
    "       'shop_history', 'minor_category_history',\n",
    "       'date_item_avg_item_cnt_lag_1', 'date_item_avg_item_cnt_lag_2',\n",
    "       'date_item_avg_item_cnt_lag_3', 'date_item_avg_item_cnt_lag_6',\n",
    "       'date_item_avg_item_cnt_lag_12', 'date_shop_avg_item_cnt_lag_1',\n",
    "       'date_shop_avg_item_cnt_lag_2', 'date_shop_avg_item_cnt_lag_3',\n",
    "       'date_shop_avg_item_cnt_lag_6', 'date_shop_avg_item_cnt_lag_12',\n",
    "       'date_shop_cat_avg_item_cnt_lag_1', 'date_cat_avg_item_cnt_lag_1',\n",
    "       'date_minor_cat_avg_item_cnt_lag_1', 'date_main_cat_avg_item_cnt_lag_1',\n",
    "       'date_city_avg_item_cnt_lag_1', 'date_item_avg_item_price_lag_1',\n",
    "       'date_item_avg_item_price_lag_2', 'date_item_avg_item_price_lag_3',\n",
    "       'date_item_avg_item_price_lag_6','item_cnt_month_log']\n",
    "\n",
    "validation = Validator(non_negative_columns = non_negative_columns)\n",
    "try:\n",
    "    validated_data = validation.fit_transform(data[:10000000])\n",
    "    print(\"Validation successful, data is valid.\")\n",
    "except ValueError as e:\n",
    "    print(f\"Validation error: {e}\")\n",
    "except TypeError as e:\n",
    "    print(f\"Type error: {e}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = DummyRegressor(strategy= 'mean')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Train/val split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RMSE for fold №1: 0.316733128831634\n",
      "RMSE for fold №2: 0.31567252021597025\n",
      "RMSE for fold №3: 0.3149302093761484\n"
     ]
    }
   ],
   "source": [
    "tss = TimeSeriesSplit(n_splits = 3)\n",
    "n = 0\n",
    "\n",
    "for train_index, validation_index in tss.split(data.loc[data.date_block_num != 34]):\n",
    "    train_data, validation_data = data.iloc[train_index], data.iloc[validation_index]\n",
    "    X_train = train_data.drop('item_cnt_month_log', axis = 1)\n",
    "    y_train = train_data['item_cnt_month_log']\n",
    "    X_val = data.drop('item_cnt_month_log', axis = 1)\n",
    "    y_val = data['item_cnt_month_log']\n",
    "\n",
    "    model.fit(X_train, y_train)\n",
    "    y_pred = model.predict(X_val)\n",
    "    rmse = root_mean_squared_error(y_pred, y_val)\n",
    "    n += 1\n",
    "    print(f'RMSE for fold №{n}: {rmse}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LinearRegression: RMSE for fold №1: 0.2552872864734364\n",
      "LinearRegression: RMSE for fold №2: 0.2287173722958028\n",
      "LinearRegression: RMSE for fold №3: 0.21534379625010117\n",
      "Mean RMSE across all splits: 0.23311615167311348\n"
     ]
    }
   ],
   "source": [
    "#Linear Regression\n",
    "from sklearn.linear_model import LinearRegression\n",
    "\n",
    "tss = TimeSeriesSplit(n_splits = 3)\n",
    "model = LinearRegression()\n",
    "rmse_scores = []\n",
    "n = 0\n",
    "\n",
    "for train_index, validation_index in tss.split(data.loc[data.date_block_num != 34]):\n",
    "    train_data, validation_data = data.iloc[train_index], data.iloc[validation_index]\n",
    "    X_train = train_data.drop('item_cnt_month_log', axis = 1)\n",
    "    y_train = train_data['item_cnt_month_log']\n",
    "    X_val = data.drop('item_cnt_month_log', axis = 1)\n",
    "    y_val = data['item_cnt_month_log']\n",
    "\n",
    "    model.fit(X_train, y_train)\n",
    "    y_pred = model.predict(X_val)\n",
    "    rmse = root_mean_squared_error(y_pred, y_val)\n",
    "    rmse_scores.append(rmse)\n",
    "    n += 1\n",
    "    print(f'LinearRegression: RMSE for fold №{n}: {rmse}')\n",
    "\n",
    "mean_rmse = np.mean(rmse_scores)\n",
    "print(f\"Mean RMSE across all splits: {mean_rmse}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "to_csv(data, 'full_data.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RMSE на тестовой выборке: 0.68\n"
     ]
    }
   ],
   "source": [
    "#Linear Regression\n",
    "from sklearn.linear_model import LinearRegression\n",
    "model = LinearRegression()\n",
    "\n",
    "train_data = data.loc[data.date_block_num != 34]\n",
    "X_train = data.drop('item_cnt_month_log', axis=1)\n",
    "y_train = data['item_cnt_month_log']\n",
    "\n",
    "\n",
    "model.fit(X_train, y_train)\n",
    "\n",
    "\n",
    "test_data = data.loc[data.date_block_num == 34]\n",
    "X_test = test_data.drop('item_cnt_month_log', axis=1)\n",
    "y_test = test_data['item_cnt_month_log']\n",
    "\n",
    "\n",
    "y_pred_test = np.round(model.predict(X_test), 1)\n",
    "\n",
    "\n",
    "rmse_test = np.sqrt(root_mean_squared_error(y_test, y_pred_test))\n",
    "print(f\"RMSE на тестовой выборке: {rmse_test:.2f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "ID = np.arange(214200)\n",
    "submission = pd.DataFrame({'ID': ID, 'item_cnt_month': y_pred_test})\n",
    "to_csv(submission, 'submission.csv')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
