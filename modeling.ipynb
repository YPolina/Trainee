{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 179,
   "metadata": {},
   "outputs": [],
   "source": [
    "import baseline\n",
    "import importlib\n",
    "importlib.reload(baseline)\n",
    "from baseline import *\n",
    "import numpy as np \n",
    "import pandas as pd\n",
    "from sklearn.preprocessing import LabelEncoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 165,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mem. usage decreased to 14.48 Mb (80.0% reduction)\n",
      "Mem. usage decreased to  1.43 Mb (70.8% reduction)\n",
      "Mem. usage decreased to  0.00 Mb (40.9% reduction)\n",
      "Mem. usage decreased to  0.27 Mb (59.4% reduction)\n",
      "Mem. usage decreased to  0.00 Mb (42.4% reduction)\n"
     ]
    }
   ],
   "source": [
    "#Data loading and reduce memory usage by changing dtypes\n",
    "train = reduce_mem_usage(pd.read_csv('train.csv'))\n",
    "test = reduce_mem_usage(pd.read_csv('test.csv'))\n",
    "shops = reduce_mem_usage(pd.read_csv('shops.csv'))\n",
    "items = reduce_mem_usage(pd.read_csv('items.csv'))\n",
    "categories = reduce_mem_usage(pd.read_csv('item_categories.csv'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 170,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Data is valid'"
      ]
     },
     "execution_count": 170,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Check if our train data is valid\n",
    "column_types = {'date_block_num': 'int8', 'shop_id': 'int8', 'item_id': 'int16', 'item_price': 'float16', 'item_cnt_day': 'float16'}\n",
    "values_ranges = {'date_block_num': (0, 33), 'shop_id': (0, 59), 'item_id': (0, 22169), 'item_price': (0.07, 42980.0), 'item_cnt_day': (0, 669)}\n",
    "Validator(column_types = column_types, value_ranges = values_ranges, check_missing = True, check_duplicates=True).fit_transform(train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 171,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Target - item_cnt_month\n",
    "target_group = (train.groupby(['date_block_num', 'shop_id', 'item_id'])['item_cnt_day']\n",
    "                .sum().rename('item_cnt_month').reset_index())\n",
    "#From EDA step we do not see linear dependency between item_cnt_month and item_price.\n",
    "#Feature 'revenue' will give us more imformation about target\n",
    "train['revenue'] = train['item_price'] * train['item_cnt_day']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 172,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "According to EDA: we do have a lot of data without full range during analysing period\n",
    "and also our test set contains shop_id&item_id pairs that are nor presented in train set at all\n",
    "'''\n",
    "columns = ['date_block_num', 'shop_id', 'item_cnt_month']\n",
    "full_data = full_data_creation(df = train, agg_group = columns, periods = train.date_block_num.nunique())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 173,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\User\\AppData\\Local\\Temp\\ipykernel_71660\\320426206.py:6: FutureWarning: The behavior of pd.concat with len(keys) != len(objs) is deprecated. In a future version this will raise instead of truncating to the smaller of the two sequences\n",
      "  full_data = pd.concat([full_data, test], keys = columns, ignore_index=True, sort = False)\n"
     ]
    }
   ],
   "source": [
    "#Merge between full data and train set\n",
    "full_data = full_data.merge(target_group, on = columns, how = 'left')\n",
    "#test set concatenation with full_data\n",
    "test['date_block_num'] = 34\n",
    "del test['ID']\n",
    "full_data = pd.concat([full_data, test], keys = columns, ignore_index=True, sort = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 174,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "We need:\n",
    "1. fill all missing values as item&shop pairs + test set have been added\n",
    "2. clip our target variable - original condition\n",
    "'''\n",
    "full_data = full_data.fillna(0)\n",
    "full_data['item_cnt_month'] = full_data['item_cnt_month'].clip(0,20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 176,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Merge with other datasets\n",
    "full_data = full_data.merge(shops, on = 'shop_id', how = 'left')\n",
    "full_data = full_data.merge(items, on = 'item_id', how = 'left')\n",
    "full_data = full_data.merge(categories, on = 'item_category_id', how = 'left')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 182,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Columns we are planning to work\n",
    "Work_columns = ['date_block_num', 'shop_id', 'item_cnt_month', 'item_id', 'city_id', 'item_category_id', 'main_category_id','minor_category_id']\n",
    "full_data = full_data.loc[:, Work_columns]\n",
    "\n",
    "#As we make transformations during DQL with shop_id, we will encode it with LabelEncoding\n",
    "full_data['shop_id'] = LabelEncoder().fit_transform(full_data['shop_id'])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
