{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "import baseline\n",
    "import importlib\n",
    "importlib.reload(baseline)\n",
    "from baseline import *\n",
    "import numpy as np \n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Data loading and reduce memory usage by changing dtypes\n",
    "files = ['train.csv', 'test.csv', 'shops.csv', 'items.csv', 'item_categories.csv']\n",
    "\n",
    "data = [loader(file_name) for file_name in files]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\User\\OneDrive\\Рабочий стол\\Trainee\\baseline.py:65: FutureWarning: The behavior of pd.concat with len(keys) != len(objs) is deprecated. In a future version this will raise instead of truncating to the smaller of the two sequences\n",
      "  \n"
     ]
    }
   ],
   "source": [
    "full_data = prepare_full_data(*data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mem. usage decreased to 105.42 Mb (82.8% reduction)\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 11054182 entries, 0 to 11054181\n",
      "Data columns (total 8 columns):\n",
      " #   Column             Dtype  \n",
      "---  ------             -----  \n",
      " 0   date_block_num     int8   \n",
      " 1   shop_id            int8   \n",
      " 2   item_cnt_month     float16\n",
      " 3   item_id            int16  \n",
      " 4   city_id            int8   \n",
      " 5   item_category_id   int8   \n",
      " 6   main_category_id   int8   \n",
      " 7   minor_category_id  int8   \n",
      "dtypes: float16(1), int16(1), int8(6)\n",
      "memory usage: 105.4 MB\n"
     ]
    }
   ],
   "source": [
    "reduce_mem_usage(full_data)\n",
    "full_data.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Data is valid'"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Check if our train data is valid\n",
    "column_types = {'date_block_num': 'int8', 'shop_id': 'int8', 'city_id': 'int8', 'item_id': 'int16', 'item_cnt_month': 'float16',\n",
    "'item_category_id': 'int8', 'main_category_id': 'int8', 'minor_category_id': 'int8'}\n",
    "values_ranges = {'date_block_num': (0, 34), 'shop_id': (0, 59), 'item_id': (0, 22169), 'item_cnt_month': (0, 669), 'city_id':(0,30),\n",
    "                'item_category_id': (0,83), 'main_category_id': (0,11), 'minor_category_id': (0, 66)}\n",
    "Validator(column_types = column_types, value_ranges = values_ranges, check_missing = True, check_duplicates=True).fit_transform(full_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Feature exctraction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "#From EDA we see a lot of missings in different features during the date period\n",
    "#We will create feature_history with number of months (for example for shop) that feature exists\n",
    "history = [('shop_id', 'shop_history'), ('item_id', 'item_history'), ('minor_category_id', 'minor_category_history')]\n",
    "for group in history:\n",
    "    full_data = history_features(df = full_data, agg = group[0], new_feature = group[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Features from aggregations\n",
    "agg_list = [\n",
    "    (['date_block_num', 'item_category_id'], 'avg_item_cnt_per_cat', {'item_cnt_month': 'mean'}),\n",
    "    (['date_block_num', 'city_id', 'shop_id'], 'avg_item_cnt_per_city_per_shop', {'item_cnt_month': 'mean'}),\n",
    "    (['date_block_num', 'shop_id'], 'avg_item_cnt_per_shop', {'item_cnt_month': 'mean'}),\n",
    "    (['date_block_num', 'item_category_id', 'shop_id'], 'avg_item_cnt_per_cat_per_shop', {'item_cnt_month': 'mean'}),\n",
    "    (['date_block_num', 'item_id'], 'avg_item_cnt_per_item', {'item_cnt_month': 'mean'}),\n",
    "    (['date_block_num', 'item_category_id', 'shop_id'], 'med_item_cnt_per_cat_per_shop', {'item_cnt_month': 'median'}),\n",
    "    (['date_block_num', 'main_category_id'], 'avg_item_cnt_per_main_cat', {'item_cnt_month': 'mean'}),\n",
    "    (['date_block_num', 'minor_category_id'], 'avg_item_cnt_per_minor_cat', {'item_cnt_month': 'mean'}),\n",
    "    (['item_id'], 'first_sales_date_block', {'item_cnt_month': 'min'})\n",
    "]\n",
    "\n",
    "\n",
    "for agg, new_col, aggregation in agg_list:\n",
    "    full_data = feat_from_agg(full_data, agg, new_col, aggregation, full_data)\n",
    "\n",
    "\n",
    "full_data['first_sales_date_block'] = full_data['first_sales_date_block'].fillna(34)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mem. usage decreased to 337.35 Mb (30.4% reduction)\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 11054182 entries, 0 to 11054181\n",
      "Data columns (total 20 columns):\n",
      " #   Column                          Dtype  \n",
      "---  ------                          -----  \n",
      " 0   date_block_num                  int8   \n",
      " 1   shop_id                         int8   \n",
      " 2   item_cnt_month                  float16\n",
      " 3   item_id                         int16  \n",
      " 4   city_id                         int8   \n",
      " 5   item_category_id                int8   \n",
      " 6   main_category_id                int8   \n",
      " 7   minor_category_id               int8   \n",
      " 8   shop_history                    int8   \n",
      " 9   item_history                    float16\n",
      " 10  minor_category_history          int8   \n",
      " 11  avg_item_cnt_per_cat            float16\n",
      " 12  avg_item_cnt_per_city_per_shop  float16\n",
      " 13  avg_item_cnt_per_shop           float16\n",
      " 14  avg_item_cnt_per_cat_per_shop   float16\n",
      " 15  avg_item_cnt_per_item           float16\n",
      " 16  med_item_cnt_per_cat_per_shop   float16\n",
      " 17  avg_item_cnt_per_main_cat       float16\n",
      " 18  avg_item_cnt_per_minor_cat      float16\n",
      " 19  first_sales_date_block          float16\n",
      "dtypes: float16(11), int16(1), int8(8)\n",
      "memory usage: 337.3 MB\n"
     ]
    }
   ],
   "source": [
    "reduce_mem_usage(full_data)\n",
    "full_data.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "full_data = feat_from_agg(df = train, agg = ['item_id'], new_col = 'item_avg_item_price', aggregation = {'item_price': ['mean']}, output_df = full_data)\n",
    "full_data['item_avg_item_price'] = full_data['item_avg_item_price'].astype(np.float16)\n",
    "\n",
    "full_data = feat_from_agg(df = train, agg = ['date_block_num','item_id'], new_col = 'date_item_avg_item_price', aggregation = {'item_price': ['mean']}, output_df = full_data)\n",
    "full_data['date_item_avg_item_price'] = full_data['date_item_avg_item_price'].astype(np.float16)\n",
    "\n",
    "full_data = lag_features(full_data, 'date_item_avg_item_price', [1])\n",
    "full_data['delta_price_lag_1'] = (full_data['date_item_avg_item_price_lag_1'] - full_data['item_avg_item_price']) / full_data['item_avg_item_price']\n",
    "\n",
    "del full_data['item_avg_item_price']\n",
    "del full_data['date_item_avg_item_price']\n",
    "del full_data['date_item_avg_item_price_lag_1']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train = train.merge(items.loc[:, ['item_id', 'item_category_id']], on = 'item_id', how = 'left')\n",
    "train = train.merge(shops.loc[:, ['shop_id', 'city_id']], on = 'shop_id', how = 'left')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Revenue and their lags\n",
    "\n",
    "agg_list = [\n",
    "    (['date_block_num', 'item_category_id', 'shop_id'], 'sales_per_category_per_shop', {'revenue': 'sum'}),\n",
    "    (['date_block_num', 'shop_id'], 'sales_per_shop', {'revenue': 'sum'}),\n",
    "    (['date_block_num', 'item_id'], 'sales_per_item', {'revenue': 'sum'}),\n",
    "]\n",
    "\n",
    "\n",
    "for agg, new_col, aggregation in agg_list:\n",
    "    full_data = feat_from_agg(train, agg, new_col, aggregation, output_df=full_data)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "lag_dict = {'sales_per_category_per_shop': [1], 'sales_per_shop': [1],\n",
    "            'sales_per_item': [1]}\n",
    "\n",
    "for feature, lags in lag_dict.items():\n",
    "    full_data = lag_features(df = full_data, col = feature, lags = lags)\n",
    "    del full_data[feature]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "#As for the item_price - delta_revenue\n",
    "full_data = feat_from_agg(df = train, agg = ['shop_id'], new_col = 'avg_sales_per_shop', aggregation = {'revenue': ['mean']}, output_df = full_data)\n",
    "full_data['avg_sales_per_shop'] = full_data['avg_sales_per_shop'].astype(np.float32)\n",
    "\n",
    "full_data['delta_revenue_lag_1'] = (full_data['sales_per_shop_lag_1'] - full_data['avg_sales_per_shop']) / full_data['avg_sales_per_shop']\n",
    "\n",
    "del full_data['avg_sales_per_shop']\n",
    "del full_data['sales_per_shop_lag_1']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Last sale feature\n",
    "full_data['last_sale'] = full_data.groupby(['shop_id', 'item_id'])['date_block_num'].shift(1)\n",
    "full_data['last_sale'] = full_data['last_sale']\n",
    "# Calculate the number of months since the last sale\n",
    "full_data['months_from_last_sale'] = full_data['date_block_num'] - full_data['last_sale']\n",
    "# Calculate the number of months since the first sale\n",
    "full_data['months_from_first_sale'] = full_data['date_block_num'] - full_data.groupby(['shop_id', 'item_id'])['date_block_num'].transform('min')\n",
    "del full_data['last_sale']\n",
    "full_data['months_from_last_sale'] = full_data['months_from_last_sale'].fillna(-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "full_data = full_data.fillna(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "full_data.to_csv('full_data.csv', index = False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Train/Test split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Validation\n",
    "tss = TimeSeriesSplit(n_splits=3)\n",
    "\n",
    "X_test = full_data[full_data.date_block_num == 34].drop('item_cnt_month', axis = 1)\n",
    "\n",
    "X = full_data[full_data.date_block_num != 34].drop('item_cnt_month', axis = 1)\n",
    "y = full_data[full_data.date_block_num != 34]['item_cnt_month']\n",
    "tss = TimeSeriesSplit(n_splits=3)\n",
    "\n",
    "for train_idxs, val_idxs in tss.split(X):\n",
    "\n",
    "    X_train, X_val = X.iloc[train_idxs], X.iloc[val_idxs]\n",
    "    y_train, y_val = y.iloc[train_idxs], y.iloc[val_idxs]\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Training\n",
    "X_train = full_data[~full_data.date_block_num.isin([33,34])]\n",
    "y_train = X_train['item_cnt_month']\n",
    "del X_train['item_cnt_month']\n",
    "\n",
    "X_val = full_data[full_data['date_block_num']==33]\n",
    "y_val = X_val['item_cnt_month']\n",
    "del X_val['item_cnt_month']\n",
    "\n",
    "X_test = full_data[full_data['date_block_num']==34].drop(columns='item_cnt_month')\n",
    "X_test = X_test.reset_index()\n",
    "del X_test['index']"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
